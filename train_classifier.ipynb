{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0981bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# from silence_tensorflow import silence_tensorflow\n",
    "# silence_tensorflow()\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.datasets import get_generators, create_classifier_dataset\n",
    "from utils.misc import log_config\n",
    "from utils.train.callbacks import Logger\n",
    "from utils.train.visualization import analyze_history\n",
    "from utils.train.classifier import load_model\n",
    "from config.datasets_config import DATASETS_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50d1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_saving():\n",
    "    # Generate save directory and store in config\n",
    "    save_dir = os.path.join(config['root_save_dir'], config['model_name'])\n",
    "    config['save_dir'] = save_dir\n",
    "\n",
    "    # Create save directory (if it does not exist)\n",
    "    try:\n",
    "        os.makedirs(save_dir, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        input_ = input('save_dir already exists, continue? (Y/n)  >> ')\n",
    "        if input_ != 'Y':\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a665416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    dataset_config['train_split'] = config['train_split']\n",
    "    dataset_config['validation_split'] = config['validation_split']\n",
    "\n",
    "    # Load data generators\n",
    "    datagen, datagen_val, datagen_test = get_generators(\n",
    "        ['train', 'val', 'test'],\n",
    "        config['image_shape'],\n",
    "        batch_size=1,  # batched later\n",
    "        random_seed=config['random_seed'],\n",
    "        dataset_config=dataset_config\n",
    "    )\n",
    "    classes = list(datagen.class_indices.keys())\n",
    "    config['classes'] = classes\n",
    "    config['num_classes'] = len(classes)\n",
    "\n",
    "    # Load class weight\n",
    "    class_weight = None\n",
    "    if config['use_class_weight']:\n",
    "        with open(os.path.join(dataset_config['dataset_dir'], 'class_weight.json'), 'r') as f:\n",
    "            class_weight = json.load(f)\n",
    "        groups = dataset_config['groups']\n",
    "        class_weight = {groups[k]: v for k, v in class_weight.items() if k in groups.keys()}\n",
    "        class_weight = {datagen.class_indices[k]: v for k, v in class_weight.items()}\n",
    "        print('Using class weights:', class_weight)\n",
    "    config['class_weight'] = class_weight\n",
    "\n",
    "    # Load datasets\n",
    "    datasets, steps = [], []\n",
    "    for gen in [datagen, datagen_val, datagen_test]:\n",
    "        ds = create_classifier_dataset(gen, config['image_shape'], len(classes))\n",
    "        ds = ds.batch(config['batch_size'])\n",
    "        ds = ds.prefetch(config['prefetch'])\n",
    "\n",
    "        steps.append(len(gen) // config['batch_size'])\n",
    "        datasets.append(ds)\n",
    "    config['steps'] = steps\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8f5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/classifier_config.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "dataset_config = DATASETS_CONFIG[config['dataset_type']]\n",
    "\n",
    "np.random.seed(config['random_seed'])\n",
    "# tf.random.set_seed(config['random_seed'])  # messes things up in encoder training, so I'm removing it here\n",
    "\n",
    "if config['model_type'] == 'vae':\n",
    "    config['latent_dim'] = 512\n",
    "    config['head_lr'] = 1e-3\n",
    "    config['encoder_lr'] = 1e-3\n",
    "\n",
    "# Barlow Twins baseline training setup\n",
    "config['model_type'] = 'resnet50'\n",
    "config['root_save_dir'] = 'trained_models/classifiers/baseline'\n",
    "config['projector_dim'] = 4096  # doesn't actually matter since the projector head is removed!\n",
    "# config['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6e52d80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 590 validated image filenames belonging to 6 classes.\n",
      "Found 23677 validated image filenames belonging to 6 classes.\n",
      "Found 20661 validated image filenames belonging to 6 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 23,577,094\n",
      "Trainable params: 23,531,654\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "Logger initialized: logs_09-27-02:12.txt\n",
      "random_seed                                        42\n",
      "epochs                                             30\n",
      "batch_size                                         256\n",
      "patience                                           None\n",
      "prefetch                                           8\n",
      "gpu_used                                           ['GPU:0', 'GPU:1', 'GPU:2', 'GPU:3']\n",
      "head_lr                                            0.03\n",
      "encoder_lr                                         0.03\n",
      "use_class_weight                                   False\n",
      "model_name                                         barlow_0.005\n",
      "root_save_dir                                      trained_models/classifiers/baseline\n",
      "model_type                                         resnet50\n",
      "projector_dim                                      4096\n",
      "latent_dim                                         64\n",
      "encoder_weights_path                               trained_models/encoders/baseline/resnet.h5\n",
      "encoder_trainable                                  True\n",
      "image_shape                                        [224, 224, 3]\n",
      "train_split                                        0.005\n",
      "validation_split                                   0.2\n",
      "dataset_type                                       tissue_6_0.3\n",
      "steps                                              [2, 92, 80]\n",
      "num_classes                                        6\n",
      "optimizer                                          sgdw\n",
      "lr_scheduler                                       cosine\n",
      "save_dir                                           trained_models/classifiers/baseline/barlow_0.005\n",
      "classes                                            ['fat', 'necrotic_debris', 'plasma_cell_infiltrate', 'stroma', 'tils', 'tumor']\n",
      "class_weight                                       None\n",
      "\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7022 - acc: 0.2617 - top_2_accuracy: 0.4941 - MCC: 0.0262 - auc: 0.4837\n",
      "Epoch 00001: val_auc improved from -inf to 0.48899, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 83s 41s/step - loss: 1.7022 - acc: 0.2617 - top_2_accuracy: 0.4941 - MCC: 0.0262 - auc: 0.4837 - val_loss: 1.6600 - val_acc: 0.3175 - val_top_2_accuracy: 0.5272 - val_MCC: 0.0259 - val_auc: 0.4890\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6118 - acc: 0.3496 - top_2_accuracy: 0.5781 - MCC: 0.0549 - auc: 0.4962\n",
      "Epoch 00002: val_auc improved from 0.48899 to 0.57940, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 73s 36s/step - loss: 1.6118 - acc: 0.3496 - top_2_accuracy: 0.5781 - MCC: 0.0549 - auc: 0.4962 - val_loss: 1.3988 - val_acc: 0.4296 - val_top_2_accuracy: 0.7561 - val_MCC: 0.0471 - val_auc: 0.5794\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3269 - acc: 0.4805 - top_2_accuracy: 0.7812 - MCC: 0.1002 - auc: 0.5831\n",
      "Epoch 00003: val_auc improved from 0.57940 to 0.71309, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 73s 36s/step - loss: 1.3269 - acc: 0.4805 - top_2_accuracy: 0.7812 - MCC: 0.1002 - auc: 0.5831 - val_loss: 1.2812 - val_acc: 0.4818 - val_top_2_accuracy: 0.7741 - val_MCC: 0.1659 - val_auc: 0.7131\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2786 - acc: 0.4844 - top_2_accuracy: 0.7539 - MCC: 0.1856 - auc: 0.7360\n",
      "Epoch 00004: val_auc improved from 0.71309 to 0.78047, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 73s 36s/step - loss: 1.2786 - acc: 0.4844 - top_2_accuracy: 0.7539 - MCC: 0.1856 - auc: 0.7360 - val_loss: 1.1704 - val_acc: 0.5647 - val_top_2_accuracy: 0.8158 - val_MCC: 0.3338 - val_auc: 0.7805\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0821 - acc: 0.6152 - top_2_accuracy: 0.8320 - MCC: 0.4020 - auc: 0.8167\n",
      "Epoch 00005: val_auc improved from 0.78047 to 0.80698, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 73s 36s/step - loss: 1.0821 - acc: 0.6152 - top_2_accuracy: 0.8320 - MCC: 0.4020 - auc: 0.8167 - val_loss: 1.0824 - val_acc: 0.5870 - val_top_2_accuracy: 0.8119 - val_MCC: 0.3761 - val_auc: 0.8070\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9498 - acc: 0.6426 - top_2_accuracy: 0.8672 - MCC: 0.4383 - auc: 0.8398\n",
      "Epoch 00006: val_auc improved from 0.80698 to 0.82179, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 73s 36s/step - loss: 0.9498 - acc: 0.6426 - top_2_accuracy: 0.8672 - MCC: 0.4383 - auc: 0.8398 - val_loss: 1.0221 - val_acc: 0.6183 - val_top_2_accuracy: 0.8432 - val_MCC: 0.4383 - val_auc: 0.8218\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9084 - acc: 0.6660 - top_2_accuracy: 0.8730 - MCC: 0.5090 - auc: 0.8579\n",
      "Epoch 00007: val_auc improved from 0.82179 to 0.84403, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.9084 - acc: 0.6660 - top_2_accuracy: 0.8730 - MCC: 0.5090 - auc: 0.8579 - val_loss: 0.9226 - val_acc: 0.6560 - val_top_2_accuracy: 0.8732 - val_MCC: 0.4841 - val_auc: 0.8440\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7818 - acc: 0.7109 - top_2_accuracy: 0.8848 - MCC: 0.5598 - auc: 0.8877\n",
      "Epoch 00008: val_auc improved from 0.84403 to 0.85121, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.7818 - acc: 0.7109 - top_2_accuracy: 0.8848 - MCC: 0.5598 - auc: 0.8877 - val_loss: 0.9206 - val_acc: 0.6603 - val_top_2_accuracy: 0.8721 - val_MCC: 0.4958 - val_auc: 0.8512\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7388 - acc: 0.7324 - top_2_accuracy: 0.8984 - MCC: 0.5911 - auc: 0.9077\n",
      "Epoch 00009: val_auc did not improve from 0.85121\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.7388 - acc: 0.7324 - top_2_accuracy: 0.8984 - MCC: 0.5911 - auc: 0.9077 - val_loss: 0.9624 - val_acc: 0.6476 - val_top_2_accuracy: 0.8702 - val_MCC: 0.4796 - val_auc: 0.8494\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7570 - acc: 0.7129 - top_2_accuracy: 0.8887 - MCC: 0.5646 - auc: 0.9086\n",
      "Epoch 00010: val_auc did not improve from 0.85121\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.7570 - acc: 0.7129 - top_2_accuracy: 0.8887 - MCC: 0.5646 - auc: 0.9086 - val_loss: 0.9641 - val_acc: 0.6470 - val_top_2_accuracy: 0.8533 - val_MCC: 0.4691 - val_auc: 0.8510\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7439 - acc: 0.7402 - top_2_accuracy: 0.8867 - MCC: 0.6074 - auc: 0.9125\n",
      "Epoch 00011: val_auc improved from 0.85121 to 0.85534, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 72s 36s/step - loss: 0.7439 - acc: 0.7402 - top_2_accuracy: 0.8867 - MCC: 0.6074 - auc: 0.9125 - val_loss: 0.9484 - val_acc: 0.6528 - val_top_2_accuracy: 0.8534 - val_MCC: 0.4791 - val_auc: 0.8553\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7613 - acc: 0.6973 - top_2_accuracy: 0.8906 - MCC: 0.5581 - auc: 0.9305\n",
      "Epoch 00012: val_auc improved from 0.85534 to 0.85670, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 73s 37s/step - loss: 0.7613 - acc: 0.6973 - top_2_accuracy: 0.8906 - MCC: 0.5581 - auc: 0.9305 - val_loss: 0.9647 - val_acc: 0.6430 - val_top_2_accuracy: 0.8506 - val_MCC: 0.4657 - val_auc: 0.8567\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7244 - acc: 0.7285 - top_2_accuracy: 0.8945 - MCC: 0.6001 - auc: 0.9268\n",
      "Epoch 00013: val_auc did not improve from 0.85670\n",
      "2/2 [==============================] - 73s 36s/step - loss: 0.7244 - acc: 0.7285 - top_2_accuracy: 0.8945 - MCC: 0.6001 - auc: 0.9268 - val_loss: 1.0980 - val_acc: 0.6188 - val_top_2_accuracy: 0.8292 - val_MCC: 0.4251 - val_auc: 0.8453\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5911 - acc: 0.7812 - top_2_accuracy: 0.9297 - MCC: 0.6793 - auc: 0.9395\n",
      "Epoch 00014: val_auc did not improve from 0.85670\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.5911 - acc: 0.7812 - top_2_accuracy: 0.9297 - MCC: 0.6793 - auc: 0.9395 - val_loss: 1.2870 - val_acc: 0.6051 - val_top_2_accuracy: 0.8156 - val_MCC: 0.4075 - val_auc: 0.8298\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6479 - acc: 0.7520 - top_2_accuracy: 0.9219 - MCC: 0.6307 - auc: 0.9351\n",
      "Epoch 00015: val_auc did not improve from 0.85670\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.6479 - acc: 0.7520 - top_2_accuracy: 0.9219 - MCC: 0.6307 - auc: 0.9351 - val_loss: 1.2765 - val_acc: 0.6169 - val_top_2_accuracy: 0.8264 - val_MCC: 0.4218 - val_auc: 0.8083\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5895 - acc: 0.7676 - top_2_accuracy: 0.9316 - MCC: 0.6509 - auc: 0.9422\n",
      "Epoch 00016: val_auc did not improve from 0.85670\n",
      "2/2 [==============================] - 73s 36s/step - loss: 0.5895 - acc: 0.7676 - top_2_accuracy: 0.9316 - MCC: 0.6509 - auc: 0.9422 - val_loss: 1.0894 - val_acc: 0.6311 - val_top_2_accuracy: 0.8328 - val_MCC: 0.4590 - val_auc: 0.8461\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5731 - acc: 0.7969 - top_2_accuracy: 0.9336 - MCC: 0.7001 - auc: 0.9520\n",
      "Epoch 00017: val_auc did not improve from 0.85670\n",
      "2/2 [==============================] - 71s 36s/step - loss: 0.5731 - acc: 0.7969 - top_2_accuracy: 0.9336 - MCC: 0.7001 - auc: 0.9520 - val_loss: 0.9955 - val_acc: 0.6586 - val_top_2_accuracy: 0.8571 - val_MCC: 0.5084 - val_auc: 0.8534\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5521 - acc: 0.7832 - top_2_accuracy: 0.9414 - MCC: 0.6754 - auc: 0.9548\n",
      "Epoch 00018: val_auc improved from 0.85670 to 0.85695, saving model to trained_models/classifiers/baseline/barlow_0.005/classifier.h5\n",
      "2/2 [==============================] - 73s 36s/step - loss: 0.5521 - acc: 0.7832 - top_2_accuracy: 0.9414 - MCC: 0.6754 - auc: 0.9548 - val_loss: 1.0222 - val_acc: 0.6572 - val_top_2_accuracy: 0.8515 - val_MCC: 0.5082 - val_auc: 0.8569\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5829 - acc: 0.7656 - top_2_accuracy: 0.9336 - MCC: 0.6562 - auc: 0.9492\n",
      "Epoch 00019: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.5829 - acc: 0.7656 - top_2_accuracy: 0.9336 - MCC: 0.6562 - auc: 0.9492 - val_loss: 1.0468 - val_acc: 0.6454 - val_top_2_accuracy: 0.8467 - val_MCC: 0.4913 - val_auc: 0.8534\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5442 - acc: 0.7969 - top_2_accuracy: 0.9414 - MCC: 0.6895 - auc: 0.9539\n",
      "Epoch 00020: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.5442 - acc: 0.7969 - top_2_accuracy: 0.9414 - MCC: 0.6895 - auc: 0.9539 - val_loss: 1.1059 - val_acc: 0.6340 - val_top_2_accuracy: 0.8357 - val_MCC: 0.4762 - val_auc: 0.8542\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5278 - acc: 0.7930 - top_2_accuracy: 0.9473 - MCC: 0.6934 - auc: 0.9560\n",
      "Epoch 00021: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.5278 - acc: 0.7930 - top_2_accuracy: 0.9473 - MCC: 0.6934 - auc: 0.9560 - val_loss: 1.1136 - val_acc: 0.6329 - val_top_2_accuracy: 0.8303 - val_MCC: 0.4695 - val_auc: 0.8510\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4981 - acc: 0.8066 - top_2_accuracy: 0.9551 - MCC: 0.7122 - auc: 0.9604\n",
      "Epoch 00022: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 73s 36s/step - loss: 0.4981 - acc: 0.8066 - top_2_accuracy: 0.9551 - MCC: 0.7122 - auc: 0.9604 - val_loss: 1.1145 - val_acc: 0.6370 - val_top_2_accuracy: 0.8287 - val_MCC: 0.4719 - val_auc: 0.8473\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5196 - acc: 0.8125 - top_2_accuracy: 0.9453 - MCC: 0.7188 - auc: 0.9578\n",
      "Epoch 00023: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 73s 36s/step - loss: 0.5196 - acc: 0.8125 - top_2_accuracy: 0.9453 - MCC: 0.7188 - auc: 0.9578 - val_loss: 1.1301 - val_acc: 0.6394 - val_top_2_accuracy: 0.8245 - val_MCC: 0.4762 - val_auc: 0.8458\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4999 - acc: 0.8145 - top_2_accuracy: 0.9492 - MCC: 0.7283 - auc: 0.9663\n",
      "Epoch 00024: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.4999 - acc: 0.8145 - top_2_accuracy: 0.9492 - MCC: 0.7283 - auc: 0.9663 - val_loss: 1.1540 - val_acc: 0.6378 - val_top_2_accuracy: 0.8205 - val_MCC: 0.4759 - val_auc: 0.8423\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4701 - acc: 0.8242 - top_2_accuracy: 0.9609 - MCC: 0.7391 - auc: 0.9681\n",
      "Epoch 00025: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.4701 - acc: 0.8242 - top_2_accuracy: 0.9609 - MCC: 0.7391 - auc: 0.9681 - val_loss: 1.1600 - val_acc: 0.6364 - val_top_2_accuracy: 0.8187 - val_MCC: 0.4723 - val_auc: 0.8429\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4883 - acc: 0.8184 - top_2_accuracy: 0.9531 - MCC: 0.7314 - auc: 0.9645\n",
      "Epoch 00026: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.4883 - acc: 0.8184 - top_2_accuracy: 0.9531 - MCC: 0.7314 - auc: 0.9645 - val_loss: 1.1914 - val_acc: 0.6359 - val_top_2_accuracy: 0.8133 - val_MCC: 0.4698 - val_auc: 0.8401\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4746 - acc: 0.8262 - top_2_accuracy: 0.9492 - MCC: 0.7389 - auc: 0.9586\n",
      "Epoch 00027: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.4746 - acc: 0.8262 - top_2_accuracy: 0.9492 - MCC: 0.7389 - auc: 0.9586 - val_loss: 1.2039 - val_acc: 0.6327 - val_top_2_accuracy: 0.8105 - val_MCC: 0.4638 - val_auc: 0.8408\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4784 - acc: 0.8223 - top_2_accuracy: 0.9590 - MCC: 0.7377 - auc: 0.9696\n",
      "Epoch 00028: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.4784 - acc: 0.8223 - top_2_accuracy: 0.9590 - MCC: 0.7377 - auc: 0.9696 - val_loss: 1.2192 - val_acc: 0.6296 - val_top_2_accuracy: 0.8077 - val_MCC: 0.4591 - val_auc: 0.8400\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4793 - acc: 0.8145 - top_2_accuracy: 0.9512 - MCC: 0.7252 - auc: 0.9659\n",
      "Epoch 00029: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 71s 36s/step - loss: 0.4793 - acc: 0.8145 - top_2_accuracy: 0.9512 - MCC: 0.7252 - auc: 0.9659 - val_loss: 1.2358 - val_acc: 0.6260 - val_top_2_accuracy: 0.8068 - val_MCC: 0.4533 - val_auc: 0.8398\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.4444 - acc: 0.8398 - top_2_accuracy: 0.9648 - MCC: 0.7610 - auc: 0.9731\n",
      "Epoch 00030: val_auc did not improve from 0.85695\n",
      "2/2 [==============================] - 72s 36s/step - loss: 0.4444 - acc: 0.8398 - top_2_accuracy: 0.9648 - MCC: 0.7610 - auc: 0.9731 - val_loss: 1.2369 - val_acc: 0.6293 - val_top_2_accuracy: 0.8065 - val_MCC: 0.4579 - val_auc: 0.8412\n",
      "80/80 [==============================] - 60s 745ms/step - loss: 1.0289 - acc: 0.6539 - top_2_accuracy: 0.8354 - MCC: 0.4884 - auc: 0.8512\n"
     ]
    }
   ],
   "source": [
    "weights_paths = ['trained_models/encoders/baseline/resnet.h5']\n",
    "\n",
    "# Trains a model for each fraction of data and save the results\n",
    "for frac in [0.005]:\n",
    "# for lr in [0.005, 0.01, 0.02, 0.05]:\n",
    "\n",
    "    for weights_path in weights_paths:\n",
    "        config['encoder_weights_path'] = weights_path\n",
    "        \n",
    "        if weights_path is None:\n",
    "            # Training parameters for supervised models\n",
    "            model_type = 'supervised'\n",
    "            config['optimizer'] = 'adam'\n",
    "            config['lr_scheduler'] = 'plateau'\n",
    "            config['head_lr'] = 5e-3\n",
    "            config['encoder_lr'] = 5e-3\n",
    "        else:\n",
    "            # Training parameters for semi-supervised models\n",
    "            model_type = 'barlow'\n",
    "            config['optimizer'] = 'sgdw'\n",
    "            config['lr_scheduler'] = 'cosine'\n",
    "            config['head_lr'] = 0.03\n",
    "            config['encoder_lr'] = 0.03\n",
    "        \n",
    "        # Hyperparameter(s) to be fine-tuned\n",
    "        config['train_split'] = frac\n",
    "\n",
    "#         config['train_split'] = 0.2\n",
    "#         config['head_lr'] = lr\n",
    "#         config['encoder_lr'] = lr\n",
    "        config['model_name'] = f'{model_type}_{frac}'\n",
    "\n",
    "        configure_saving()\n",
    "\n",
    "        # Load dataset and model\n",
    "        datasets = load_datasets()\n",
    "        model = load_model(config_dict=config)\n",
    "\n",
    "        # Create training callbacks\n",
    "        callbacks = []\n",
    "        if config['patience'] is not None:\n",
    "            es = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=config['patience'])\n",
    "            callbacks.append(es)\n",
    "\n",
    "        if config['lr_scheduler'] == 'plateau':\n",
    "            reduce = ReduceLROnPlateau(\n",
    "                monitor='val_auc',\n",
    "                factor=0.2,\n",
    "                patience=3,\n",
    "                verbose=1\n",
    "            )\n",
    "            callbacks.append(reduce)\n",
    "\n",
    "        mc = ModelCheckpoint(\n",
    "            os.path.join(config['save_dir'], 'classifier.h5'),\n",
    "            monitor='val_auc', \n",
    "            mode='max',\n",
    "            verbose=1,\n",
    "            save_best_only=True, save_weights_only=True\n",
    "        )\n",
    "        callbacks.append(mc)\n",
    "        \n",
    "        callbacks.append(Logger())\n",
    "\n",
    "        # Print and save the configuration\n",
    "        log_config(config, save_config=True)\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            datasets[0],\n",
    "            epochs=config['epochs'],\n",
    "            steps_per_epoch=config['steps'][0],\n",
    "            validation_steps=config['steps'][1],\n",
    "            validation_data=datasets[1],\n",
    "            callbacks=callbacks,\n",
    "            class_weight=config['class_weight']\n",
    "        )\n",
    "\n",
    "        # Save the training history\n",
    "        with open(os.path.join(config['save_dir'], 'history.pickle'), 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # Load best model, save encoder weights (separately), and evaluate model\n",
    "        model.load_weights(os.path.join(config['save_dir'], 'classifier.h5'))\n",
    "        model.layers[1].save_weights(os.path.join(config['save_dir'], 'encoder.h5'))\n",
    "        model.evaluate(datasets[2], steps=config['steps'][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
