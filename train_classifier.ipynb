{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# from silence_tensorflow import silence_tensorflow\n",
    "# silence_tensorflow()\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow_addons.metrics import MatthewsCorrelationCoefficient\n",
    "from tensorflow_addons.optimizers import SGDW, MultiOptimizer, Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.datasets import get_generators, create_classifier_dataset\n",
    "from utils.train import lr_scheduler\n",
    "from utils.models import resnet_cifar, resnet, vae\n",
    "from utils.misc import log_config\n",
    "from config.datasets_config import DATASETS_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2344b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_saving():\n",
    "    # Generate save directory and store in config\n",
    "    save_dir = os.path.join(config['root_save_dir'], config['model_name'])\n",
    "    config['save_dir'] = save_dir\n",
    "\n",
    "    # Create save directory (if it does not exist)\n",
    "    try:\n",
    "        os.makedirs(save_dir, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        input_ = input('save_dir already exists, continue? (Y/n)  >> ')\n",
    "        if input_ != 'Y':\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7ef687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    dataset_config['train_split'] = config['train_split']\n",
    "    dataset_config['validation_split'] = config['validation_split']\n",
    "\n",
    "    # Load data generators\n",
    "    datagen, datagen_val, datagen_test = get_generators(\n",
    "        ['train', 'val', 'test'],\n",
    "        config['image_shape'],\n",
    "        batch_size=1,  # batched later\n",
    "        random_seed=config['random_seed'],\n",
    "        dataset_config=dataset_config\n",
    "    )\n",
    "    classes = list(datagen.class_indices.keys())\n",
    "    config['classes'] = classes\n",
    "    config['num_classes'] = len(classes)\n",
    "\n",
    "    # Load class weight\n",
    "    class_weight = None\n",
    "    if config['use_class_weight']:\n",
    "        with open(os.path.join(dataset_config['dataset_dir'], 'class_weight.json'), 'r') as f:\n",
    "            class_weight = json.load(f)\n",
    "        groups = dataset_config['groups']\n",
    "        class_weight = {groups[k]: v for k, v in class_weight.items() if k in groups.keys()}\n",
    "        class_weight = {datagen.class_indices[k]: v for k, v in class_weight.items()}\n",
    "        print('Using class weights:', class_weight)\n",
    "    config['class_weight'] = class_weight\n",
    "\n",
    "    # Load datasets\n",
    "    datasets, steps = [], []\n",
    "    for gen in [datagen, datagen_val, datagen_test]:\n",
    "        ds = create_classifier_dataset(gen, config['image_shape'], len(classes))\n",
    "        ds = ds.batch(config['batch_size'])\n",
    "        ds = ds.prefetch(config['prefetch'])\n",
    "\n",
    "        steps.append(len(gen) // config['batch_size'])\n",
    "        datasets.append(ds)\n",
    "    config['steps'] = steps\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(config_dict, base_lr):\n",
    "    if config_dict['lr_scheduler'] == 'cosine':\n",
    "        lr_fn = lr_scheduler.get_decay_fn(\n",
    "            base_lr=base_lr,\n",
    "            epochs=config_dict['epochs'],\n",
    "            steps_per_epoch=config_dict['steps'][0]\n",
    "        )\n",
    "    elif config_dict['lr_scheduler'] == 'plateau':\n",
    "        lr_fn = ReduceLROnPlateau(\n",
    "            monitor='val_acc',\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    if config_dict['optimizer'] == 'adam':\n",
    "        return Adam(learning_rate=lr_fn)\n",
    "    elif config_dict['optimizer'] == 'sgdw':\n",
    "        return SGDW(learning_rate=lr_fn, momentum=0.9, weight_decay=0)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def load_model(config_dict, evaluation=False):\n",
    "    \"\"\"\n",
    "    @param config_dict:     the configuration for the model\n",
    "    @param evaluation:      whether or not the model is loaded for testing\n",
    "    @return:                classification model\n",
    "    \"\"\"\n",
    "    strategy = tf.distribute.MirroredStrategy(config_dict['gpu_used'])\n",
    "    print('Number of devices:', strategy.num_replicas_in_sync)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Build model (and load pretrained weights)\n",
    "        model_build_functions = {\n",
    "            'cifar': resnet_cifar.get_classifier,\n",
    "            'resnet50': resnet.get_classifier,\n",
    "            'vae': vae.get_classifier\n",
    "        }\n",
    "        model = model_build_functions[config['model_type']](config_dict)\n",
    "\n",
    "        # Set up optimizers\n",
    "        optimizers_and_layers = [\n",
    "            (get_optimizer(config_dict, config_dict['encoder_lr']), model.layers[1]),  # encoder\n",
    "            (get_optimizer(config_dict, config_dict['head_lr']), model.layers[2])      # classification head\n",
    "        ]\n",
    "        optimizer = MultiOptimizer(optimizers_and_layers)\n",
    "\n",
    "        # Print model summary and compile model\n",
    "        print()\n",
    "        model.summary()\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'acc',\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"top_2_accuracy\"),\n",
    "                MatthewsCorrelationCoefficient(num_classes=config_dict['num_classes'], name='MCC')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86196d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/classifier_config.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "dataset_config = DATASETS_CONFIG[config['dataset_type']]\n",
    "\n",
    "np.random.seed(config['random_seed'])\n",
    "tf.random.set_seed(config['random_seed'])\n",
    "\n",
    "config['model_type'] = 'vae'\n",
    "config['model_name'] = 'supervised_vae'\n",
    "config['encoder_weights_path'] = None\n",
    "\n",
    "# config['pretrained_dir'] = 'trained_models/vaes/vae_100'\n",
    "# config['encoder_weights_path'] = os.path.join(config['pretrained_dir'], 'encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30a143b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['encoder_trainable'] = True  # not implemented\n",
    "config['lr_schedular'] = 'plateau'  # not implemented\n",
    "config['optimizer'] = 'adam'  # not implemented\n",
    "\n",
    "# Each model type has different optimal learning rates\n",
    "if config['model_type'] == 'vae':\n",
    "    config['latent_dim'] = 512\n",
    "    config['head_lr'] = 5e-4\n",
    "    config['encoder_lr'] = 5e-4\n",
    "    \n",
    "elif config['model_type'].startswith('barlow'):\n",
    "    config['head_lr'] = 0.5\n",
    "    config['encoder_lr'] = 0.5\n",
    "    \n",
    "elif config['model_type'] == 'supervised':\n",
    "    config['head_lr'] = 0.01\n",
    "    config['encoder_lr'] = 0.01\n",
    "    config['pretrained_dir'] = None\n",
    "    config['encoder_weights_path'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68f1e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir already exists, continue? (Y/n)  >> Y\n",
      "Found 11883 validated image filenames belonging to 8 classes.\n",
      "Found 17829 validated image filenames belonging to 8 classes.\n",
      "Found 20679 validated image filenames belonging to 8 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "projector (Sequential)       (None, 1024)              14945472  \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 14,953,672\n",
      "Trainable params: 14,950,664\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n",
      "random_seed                                        42\n",
      "epochs                                             30\n",
      "batch_size                                         256\n",
      "patience                                           None\n",
      "prefetch                                           8\n",
      "gpu_used                                           ['GPU:0', 'GPU:1', 'GPU:2', 'GPU:3']\n",
      "head_lr                                            0.0005\n",
      "encoder_lr                                         0.0005\n",
      "use_class_weight                                   False\n",
      "root_save_dir                                      trained_models/classifiers\n",
      "encoder_type                                       resnet50\n",
      "model_type                                         vae\n",
      "projector_dim                                      2048\n",
      "latent_dim                                         512\n",
      "pretrained_dir                                     None\n",
      "image_shape                                        [224, 224, 3]\n",
      "train_split                                        0.1\n",
      "validation_split                                   0.15\n",
      "dataset_type                                       tissue_8_0.3\n",
      "steps_per_epoch                                    None\n",
      "num_classes                                        8\n",
      "model_name                                         supervised_vae\n",
      "encoder_weights_path                               None\n",
      "encoder_trainable                                  True\n",
      "optimizer                                          adam\n",
      "lr_schedular                                       plateau\n",
      "save_dir                                           trained_models/classifiers/supervised_vae\n",
      "classes                                            ['blood', 'blood_vessel', 'fat', 'necrotic_debris', 'plasma_cell_infiltrate', 'stroma', 'tils', 'tumor']\n",
      "class_weight                                       None\n",
      "steps                                              [46, 69, 80]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configure_saving()\n",
    "\n",
    "# Load dataset and model\n",
    "datasets = load_datasets()\n",
    "model = load_model(config_dict=config)\n",
    "\n",
    "# Create training callbacks\n",
    "callbacks = []\n",
    "if config['patience'] is not None:\n",
    "    es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=config['patience'])\n",
    "    callbacks.append(es)\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    os.path.join(config['save_dir'], 'classifier.h5'),\n",
    "    monitor='val_acc', mode='max',\n",
    "    verbose=1,\n",
    "    save_best_only=True, save_weights_only=True\n",
    ")\n",
    "callbacks.append(mc)\n",
    "\n",
    "# Print and save the configuration\n",
    "log_config(config, save_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301508af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.4111 - acc: 0.5279 - top_2_accuracy: 0.7140 - MCC: 0.3114\n",
      "Epoch 00001: val_acc improved from -inf to 0.42759, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 90s 2s/step - loss: 1.4111 - acc: 0.5279 - top_2_accuracy: 0.7140 - MCC: 0.3114 - val_loss: 1.6341 - val_acc: 0.4276 - val_top_2_accuracy: 0.7636 - val_MCC: 0.0000e+00\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.8843 - acc: 0.6838 - top_2_accuracy: 0.8829 - MCC: 0.5227\n",
      "Epoch 00002: val_acc improved from 0.42759 to 0.42873, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 81s 2s/step - loss: 0.8843 - acc: 0.6838 - top_2_accuracy: 0.8829 - MCC: 0.5227 - val_loss: 1.6557 - val_acc: 0.4287 - val_top_2_accuracy: 0.7636 - val_MCC: 0.0000e+00\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.7494 - acc: 0.7321 - top_2_accuracy: 0.9025 - MCC: 0.5968\n",
      "Epoch 00003: val_acc did not improve from 0.42873\n",
      "46/46 [==============================] - 81s 2s/step - loss: 0.7494 - acc: 0.7321 - top_2_accuracy: 0.9025 - MCC: 0.5968 - val_loss: 1.9988 - val_acc: 0.4267 - val_top_2_accuracy: 0.7635 - val_MCC: 0.0000e+00\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6524 - acc: 0.7706 - top_2_accuracy: 0.9198 - MCC: 0.6556\n",
      "Epoch 00004: val_acc did not improve from 0.42873\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.6524 - acc: 0.7706 - top_2_accuracy: 0.9198 - MCC: 0.6556 - val_loss: 2.3994 - val_acc: 0.4259 - val_top_2_accuracy: 0.7609 - val_MCC: 0.0000e+00\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5940 - acc: 0.7942 - top_2_accuracy: 0.9318 - MCC: 0.6925\n",
      "Epoch 00005: val_acc did not improve from 0.42873\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.5940 - acc: 0.7942 - top_2_accuracy: 0.9318 - MCC: 0.6925 - val_loss: 2.6755 - val_acc: 0.4255 - val_top_2_accuracy: 0.7615 - val_MCC: 0.0000e+00\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5222 - acc: 0.8261 - top_2_accuracy: 0.9442 - MCC: 0.7407\n",
      "Epoch 00006: val_acc improved from 0.42873 to 0.42963, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 81s 2s/step - loss: 0.5222 - acc: 0.8261 - top_2_accuracy: 0.9442 - MCC: 0.7407 - val_loss: 2.6858 - val_acc: 0.4296 - val_top_2_accuracy: 0.7653 - val_MCC: 0.0054\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4719 - acc: 0.8444 - top_2_accuracy: 0.9541 - MCC: 0.7686\n",
      "Epoch 00007: val_acc improved from 0.42963 to 0.43167, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.4719 - acc: 0.8444 - top_2_accuracy: 0.9541 - MCC: 0.7686 - val_loss: 2.4215 - val_acc: 0.4317 - val_top_2_accuracy: 0.7677 - val_MCC: 0.0440\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4243 - acc: 0.8697 - top_2_accuracy: 0.9629 - MCC: 0.8075\n",
      "Epoch 00008: val_acc improved from 0.43167 to 0.43399, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.4243 - acc: 0.8697 - top_2_accuracy: 0.9629 - MCC: 0.8075 - val_loss: 2.4511 - val_acc: 0.4340 - val_top_2_accuracy: 0.7771 - val_MCC: 0.0778\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3803 - acc: 0.8894 - top_2_accuracy: 0.9707 - MCC: 0.8365\n",
      "Epoch 00009: val_acc improved from 0.43399 to 0.48319, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.3803 - acc: 0.8894 - top_2_accuracy: 0.9707 - MCC: 0.8365 - val_loss: 1.9442 - val_acc: 0.4832 - val_top_2_accuracy: 0.7890 - val_MCC: 0.2292\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3407 - acc: 0.9095 - top_2_accuracy: 0.9766 - MCC: 0.8667\n",
      "Epoch 00010: val_acc improved from 0.48319 to 0.56278, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.3407 - acc: 0.9095 - top_2_accuracy: 0.9766 - MCC: 0.8667 - val_loss: 1.5409 - val_acc: 0.5628 - val_top_2_accuracy: 0.8035 - val_MCC: 0.3481\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3081 - acc: 0.9220 - top_2_accuracy: 0.9805 - MCC: 0.8855\n",
      "Epoch 00011: val_acc did not improve from 0.56278\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.3081 - acc: 0.9220 - top_2_accuracy: 0.9805 - MCC: 0.8855 - val_loss: 1.5579 - val_acc: 0.5412 - val_top_2_accuracy: 0.8160 - val_MCC: 0.3230\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2826 - acc: 0.9331 - top_2_accuracy: 0.9843 - MCC: 0.9016\n",
      "Epoch 00012: val_acc improved from 0.56278 to 0.58339, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.2826 - acc: 0.9331 - top_2_accuracy: 0.9843 - MCC: 0.9016 - val_loss: 1.4029 - val_acc: 0.5834 - val_top_2_accuracy: 0.8253 - val_MCC: 0.3785\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2541 - acc: 0.9482 - top_2_accuracy: 0.9879 - MCC: 0.9241\n",
      "Epoch 00013: val_acc improved from 0.58339 to 0.64521, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.2541 - acc: 0.9482 - top_2_accuracy: 0.9879 - MCC: 0.9241 - val_loss: 1.0783 - val_acc: 0.6452 - val_top_2_accuracy: 0.8602 - val_MCC: 0.4657\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2361 - acc: 0.9550 - top_2_accuracy: 0.9900 - MCC: 0.9342\n",
      "Epoch 00014: val_acc did not improve from 0.64521\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.2361 - acc: 0.9550 - top_2_accuracy: 0.9900 - MCC: 0.9342 - val_loss: 1.2928 - val_acc: 0.6064 - val_top_2_accuracy: 0.8372 - val_MCC: 0.4139\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2195 - acc: 0.9630 - top_2_accuracy: 0.9922 - MCC: 0.9459\n",
      "Epoch 00015: val_acc improved from 0.64521 to 0.67680, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 81s 2s/step - loss: 0.2195 - acc: 0.9630 - top_2_accuracy: 0.9922 - MCC: 0.9459 - val_loss: 0.9357 - val_acc: 0.6768 - val_top_2_accuracy: 0.8831 - val_MCC: 0.5051\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2062 - acc: 0.9673 - top_2_accuracy: 0.9931 - MCC: 0.9522\n",
      "Epoch 00016: val_acc did not improve from 0.67680\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.2062 - acc: 0.9673 - top_2_accuracy: 0.9931 - MCC: 0.9522 - val_loss: 1.0245 - val_acc: 0.6590 - val_top_2_accuracy: 0.8632 - val_MCC: 0.4892\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1886 - acc: 0.9758 - top_2_accuracy: 0.9953 - MCC: 0.9646\n",
      "Epoch 00017: val_acc did not improve from 0.67680\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1886 - acc: 0.9758 - top_2_accuracy: 0.9953 - MCC: 0.9646 - val_loss: 0.9687 - val_acc: 0.6747 - val_top_2_accuracy: 0.8729 - val_MCC: 0.5083\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1803 - acc: 0.9753 - top_2_accuracy: 0.9952 - MCC: 0.9640\n",
      "Epoch 00018: val_acc improved from 0.67680 to 0.68037, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1803 - acc: 0.9753 - top_2_accuracy: 0.9952 - MCC: 0.9640 - val_loss: 0.9294 - val_acc: 0.6804 - val_top_2_accuracy: 0.8783 - val_MCC: 0.5172\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1708 - acc: 0.9804 - top_2_accuracy: 0.9958 - MCC: 0.9715\n",
      "Epoch 00019: val_acc improved from 0.68037 to 0.68139, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1708 - acc: 0.9804 - top_2_accuracy: 0.9958 - MCC: 0.9715 - val_loss: 0.9302 - val_acc: 0.6814 - val_top_2_accuracy: 0.8779 - val_MCC: 0.5245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1640 - acc: 0.9823 - top_2_accuracy: 0.9961 - MCC: 0.9740\n",
      "Epoch 00020: val_acc did not improve from 0.68139\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1640 - acc: 0.9823 - top_2_accuracy: 0.9961 - MCC: 0.9740 - val_loss: 0.9468 - val_acc: 0.6792 - val_top_2_accuracy: 0.8777 - val_MCC: 0.5170\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1587 - acc: 0.9839 - top_2_accuracy: 0.9966 - MCC: 0.9765\n",
      "Epoch 00021: val_acc did not improve from 0.68139\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1587 - acc: 0.9839 - top_2_accuracy: 0.9966 - MCC: 0.9765 - val_loss: 0.9806 - val_acc: 0.6693 - val_top_2_accuracy: 0.8708 - val_MCC: 0.5003\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1535 - acc: 0.9838 - top_2_accuracy: 0.9971 - MCC: 0.9764\n",
      "Epoch 00022: val_acc did not improve from 0.68139\n",
      "46/46 [==============================] - 81s 2s/step - loss: 0.1535 - acc: 0.9838 - top_2_accuracy: 0.9971 - MCC: 0.9764 - val_loss: 0.9408 - val_acc: 0.6812 - val_top_2_accuracy: 0.8777 - val_MCC: 0.5197\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1534 - acc: 0.9842 - top_2_accuracy: 0.9969 - MCC: 0.9770\n",
      "Epoch 00023: val_acc improved from 0.68139 to 0.68212, saving model to trained_models/classifiers/supervised_vae/classifier.h5\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1534 - acc: 0.9842 - top_2_accuracy: 0.9969 - MCC: 0.9770 - val_loss: 0.9496 - val_acc: 0.6821 - val_top_2_accuracy: 0.8732 - val_MCC: 0.5221\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1458 - acc: 0.9858 - top_2_accuracy: 0.9972 - MCC: 0.9793\n",
      "Epoch 00024: val_acc did not improve from 0.68212\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1458 - acc: 0.9858 - top_2_accuracy: 0.9972 - MCC: 0.9793 - val_loss: 0.9429 - val_acc: 0.6790 - val_top_2_accuracy: 0.8762 - val_MCC: 0.5178\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1457 - acc: 0.9879 - top_2_accuracy: 0.9975 - MCC: 0.9824\n",
      "Epoch 00025: val_acc did not improve from 0.68212\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1457 - acc: 0.9879 - top_2_accuracy: 0.9975 - MCC: 0.9824 - val_loss: 0.9501 - val_acc: 0.6753 - val_top_2_accuracy: 0.8739 - val_MCC: 0.5129\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1442 - acc: 0.9873 - top_2_accuracy: 0.9973 - MCC: 0.9816\n",
      "Epoch 00026: val_acc did not improve from 0.68212\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1442 - acc: 0.9873 - top_2_accuracy: 0.9973 - MCC: 0.9816 - val_loss: 0.9309 - val_acc: 0.6806 - val_top_2_accuracy: 0.8778 - val_MCC: 0.5197\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1443 - acc: 0.9872 - top_2_accuracy: 0.9970 - MCC: 0.9813\n",
      "Epoch 00027: val_acc did not improve from 0.68212\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1443 - acc: 0.9872 - top_2_accuracy: 0.9970 - MCC: 0.9813 - val_loss: 0.9416 - val_acc: 0.6782 - val_top_2_accuracy: 0.8756 - val_MCC: 0.5193\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1424 - acc: 0.9879 - top_2_accuracy: 0.9975 - MCC: 0.9823\n",
      "Epoch 00028: val_acc did not improve from 0.68212\n",
      "46/46 [==============================] - 80s 2s/step - loss: 0.1424 - acc: 0.9879 - top_2_accuracy: 0.9975 - MCC: 0.9823 - val_loss: 0.9432 - val_acc: 0.6821 - val_top_2_accuracy: 0.8761 - val_MCC: 0.5212\n",
      "Epoch 29/30\n",
      "16/46 [=========>....................] - ETA: 8s - loss: 0.1419 - acc: 0.9883 - top_2_accuracy: 0.9963 - MCC: 0.9831"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    datasets[0],\n",
    "    epochs=config['epochs'],\n",
    "    steps_per_epoch=config['steps'][0],\n",
    "    validation_steps=config['steps'][1],\n",
    "    validation_data=datasets[1],\n",
    "    callbacks=callbacks,\n",
    "    class_weight=config['class_weight']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3402f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir already exists, continue? (Y/n)  >> Y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trained_models/classifiers/vae_100'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configure_saving()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6a5d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 76s 953ms/step - loss: 0.8595 - acc: 0.6762 - top_2_accuracy: 0.8864 - MCC: 0.5166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8594774007797241, 0.6761718988418579, 0.8863769769668579, 0.516628623008728]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the training history\n",
    "with open(os.path.join(config['save_dir'], 'history.pickle'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# Load best model, save encoder weights (separately), and evaluate model\n",
    "model.load_weights(os.path.join(config['save_dir'], 'classifier.h5'))\n",
    "model.layers[1].save_weights(os.path.join(config['save_dir'], 'encoder.h5'))\n",
    "model.evaluate(datasets[2], steps=config['steps'][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
