{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5862c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# from silence_tensorflow import silence_tensorflow\n",
    "# silence_tensorflow()\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.datasets import get_generators, create_classifier_dataset\n",
    "from utils.misc import log_config\n",
    "from utils.train.callbacks import Logger\n",
    "from utils.train.visualization import analyze_history\n",
    "from utils.train.classifier import load_model\n",
    "from config.datasets_config import DATASETS_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a0b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_saving():\n",
    "    # Generate save directory and store in config\n",
    "    save_dir = os.path.join(config['root_save_dir'], config['model_name'])\n",
    "    config['save_dir'] = save_dir\n",
    "\n",
    "    # Create save directory (if it does not exist)\n",
    "    try:\n",
    "        os.makedirs(save_dir, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        input_ = input('save_dir already exists, continue? (Y/n)  >> ')\n",
    "        if input_ != 'Y':\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721b7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    dataset_config['train_split'] = config['train_split']\n",
    "    dataset_config['validation_split'] = config['validation_split']\n",
    "\n",
    "    # Load data generators\n",
    "    datagen, datagen_val, datagen_test = get_generators(\n",
    "        ['train', 'val', 'test'],\n",
    "        config['image_shape'],\n",
    "        batch_size=1,  # batched later\n",
    "        random_seed=config['random_seed'],\n",
    "        dataset_config=dataset_config\n",
    "    )\n",
    "    classes = list(datagen.class_indices.keys())\n",
    "    config['classes'] = classes\n",
    "    config['num_classes'] = len(classes)\n",
    "\n",
    "    # Load class weight\n",
    "    class_weight = None\n",
    "    if config['use_class_weight']:\n",
    "        with open(os.path.join(dataset_config['dataset_dir'], 'class_weight.json'), 'r') as f:\n",
    "            class_weight = json.load(f)\n",
    "        groups = dataset_config['groups']\n",
    "        class_weight = {groups[k]: v for k, v in class_weight.items() if k in groups.keys()}\n",
    "        class_weight = {datagen.class_indices[k]: v for k, v in class_weight.items()}\n",
    "        print('Using class weights:', class_weight)\n",
    "    config['class_weight'] = class_weight\n",
    "\n",
    "    # Load datasets\n",
    "    datasets, steps = [], []\n",
    "    for gen in [datagen, datagen_val, datagen_test]:\n",
    "        ds = create_classifier_dataset(gen, config['image_shape'], len(classes))\n",
    "        ds = ds.batch(config['batch_size'])\n",
    "        ds = ds.prefetch(config['prefetch'])\n",
    "\n",
    "        steps.append(len(gen) // config['batch_size'])\n",
    "        datasets.append(ds)\n",
    "    config['steps'] = steps\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87cd5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/classifier_config.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "dataset_config = DATASETS_CONFIG[config['dataset_type']]\n",
    "\n",
    "np.random.seed(config['random_seed'])\n",
    "# tf.random.set_seed(config['random_seed'])  # messes things up in encoder training, so I'm removing it here\n",
    "\n",
    "if config['model_type'] == 'vae':\n",
    "    config['latent_dim'] = 512\n",
    "    config['head_lr'] = 1e-3\n",
    "    config['encoder_lr'] = 1e-3\n",
    "\n",
    "# Barlow Twins baseline training setup\n",
    "config['model_type'] = 'resnet50'\n",
    "config['root_save_dir'] = 'trained_models/classifiers/lamb_100_4096_256_imagenet_lr'\n",
    "config['projector_dim'] = 4096  # doesn't actually matter since the projector head is removed!\n",
    "# config['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12adbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23676 validated image filenames belonging to 6 classes.\n",
      "Found 23677 validated image filenames belonging to 6 classes.\n",
      "Found 20661 validated image filenames belonging to 6 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 23,577,094\n",
      "Trainable params: 23,531,654\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "Logger initialized: logs_09-10-17:55.txt\n",
      "random_seed                                        42\n",
      "epochs                                             30\n",
      "batch_size                                         256\n",
      "patience                                           None\n",
      "prefetch                                           8\n",
      "gpu_used                                           ['GPU:0', 'GPU:1', 'GPU:2', 'GPU:3']\n",
      "head_lr                                            0.005\n",
      "encoder_lr                                         0.005\n",
      "use_class_weight                                   False\n",
      "model_name                                         barlow_0.005\n",
      "root_save_dir                                      trained_models/classifiers/lamb_100_4096_256_imagenet_lr\n",
      "model_type                                         resnet50\n",
      "projector_dim                                      4096\n",
      "latent_dim                                         64\n",
      "encoder_weights_path                               trained_models/encoders/lamb_100_4096_256_imagenet/resnet.h5\n",
      "encoder_trainable                                  True\n",
      "image_shape                                        [224, 224, 3]\n",
      "train_split                                        0.2\n",
      "validation_split                                   0.2\n",
      "dataset_type                                       tissue_6_0.3\n",
      "steps                                              [92, 92, 80]\n",
      "num_classes                                        6\n",
      "optimizer                                          sgdw\n",
      "lr_scheduler                                       cosine\n",
      "save_dir                                           trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005\n",
      "classes                                            ['fat', 'necrotic_debris', 'plasma_cell_infiltrate', 'stroma', 'tils', 'tumor']\n",
      "class_weight                                       None\n",
      "\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 172 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:batch_all_reduce: 172 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.7273 - acc: 0.2792 - top_2_accuracy: 0.4712 - MCC: 0.1167 - auc: 0.6106\n",
      "Epoch 00001: val_auc improved from -inf to 0.68191, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 151s 2s/step - loss: 1.7273 - acc: 0.2792 - top_2_accuracy: 0.4712 - MCC: 0.1167 - auc: 0.6106 - val_loss: 1.5228 - val_acc: 0.4975 - val_top_2_accuracy: 0.7020 - val_MCC: 0.2836 - val_auc: 0.6819\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.2368 - acc: 0.6330 - top_2_accuracy: 0.8125 - MCC: 0.4481 - auc: 0.7831\n",
      "Epoch 00002: val_auc improved from 0.68191 to 0.85009, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 141s 2s/step - loss: 1.2368 - acc: 0.6330 - top_2_accuracy: 0.8125 - MCC: 0.4481 - auc: 0.7831 - val_loss: 0.9764 - val_acc: 0.6968 - val_top_2_accuracy: 0.8703 - val_MCC: 0.5424 - val_auc: 0.8501\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.8561 - acc: 0.7258 - top_2_accuracy: 0.8905 - MCC: 0.5859 - auc: 0.8849\n",
      "Epoch 00003: val_auc improved from 0.85009 to 0.90378, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 140s 2s/step - loss: 0.8561 - acc: 0.7258 - top_2_accuracy: 0.8905 - MCC: 0.5859 - auc: 0.8849 - val_loss: 0.7736 - val_acc: 0.7646 - val_top_2_accuracy: 0.9081 - val_MCC: 0.6491 - val_auc: 0.9038\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.6651 - acc: 0.7782 - top_2_accuracy: 0.9181 - MCC: 0.6687 - auc: 0.9247\n",
      "Epoch 00004: val_auc improved from 0.90378 to 0.92785, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 139s 2s/step - loss: 0.6651 - acc: 0.7782 - top_2_accuracy: 0.9181 - MCC: 0.6687 - auc: 0.9247 - val_loss: 0.6940 - val_acc: 0.7888 - val_top_2_accuracy: 0.9243 - val_MCC: 0.6922 - val_auc: 0.9279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5599 - acc: 0.8099 - top_2_accuracy: 0.9346 - MCC: 0.7179 - auc: 0.9460\n",
      "Epoch 00005: val_auc improved from 0.92785 to 0.93922, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.5599 - acc: 0.8099 - top_2_accuracy: 0.9346 - MCC: 0.7179 - auc: 0.9460 - val_loss: 0.6483 - val_acc: 0.8053 - val_top_2_accuracy: 0.9317 - val_MCC: 0.7165 - val_auc: 0.9392\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5025 - acc: 0.8252 - top_2_accuracy: 0.9440 - MCC: 0.7410 - auc: 0.9557\n",
      "Epoch 00006: val_auc improved from 0.93922 to 0.94615, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.5025 - acc: 0.8252 - top_2_accuracy: 0.9440 - MCC: 0.7410 - auc: 0.9557 - val_loss: 0.5972 - val_acc: 0.8163 - val_top_2_accuracy: 0.9418 - val_MCC: 0.7313 - val_auc: 0.9461\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4631 - acc: 0.8381 - top_2_accuracy: 0.9499 - MCC: 0.7600 - auc: 0.9631\n",
      "Epoch 00007: val_auc improved from 0.94615 to 0.95178, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 139s 2s/step - loss: 0.4631 - acc: 0.8381 - top_2_accuracy: 0.9499 - MCC: 0.7600 - auc: 0.9631 - val_loss: 0.5732 - val_acc: 0.8241 - val_top_2_accuracy: 0.9437 - val_MCC: 0.7406 - val_auc: 0.9518\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4330 - acc: 0.8489 - top_2_accuracy: 0.9548 - MCC: 0.7774 - auc: 0.9678\n",
      "Epoch 00008: val_auc improved from 0.95178 to 0.95544, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.4330 - acc: 0.8489 - top_2_accuracy: 0.9548 - MCC: 0.7774 - auc: 0.9678 - val_loss: 0.5500 - val_acc: 0.8311 - val_top_2_accuracy: 0.9491 - val_MCC: 0.7513 - val_auc: 0.9554\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4015 - acc: 0.8587 - top_2_accuracy: 0.9596 - MCC: 0.7911 - auc: 0.9724\n",
      "Epoch 00009: val_auc improved from 0.95544 to 0.95719, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 138s 1s/step - loss: 0.4015 - acc: 0.8587 - top_2_accuracy: 0.9596 - MCC: 0.7911 - auc: 0.9724 - val_loss: 0.5308 - val_acc: 0.8328 - val_top_2_accuracy: 0.9498 - val_MCC: 0.7531 - val_auc: 0.9572\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.3748 - acc: 0.8669 - top_2_accuracy: 0.9626 - MCC: 0.8041 - auc: 0.9764\n",
      "Epoch 00010: val_auc improved from 0.95719 to 0.95820, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 139s 2s/step - loss: 0.3748 - acc: 0.8669 - top_2_accuracy: 0.9626 - MCC: 0.8041 - auc: 0.9764 - val_loss: 0.5331 - val_acc: 0.8391 - val_top_2_accuracy: 0.9532 - val_MCC: 0.7630 - val_auc: 0.9582\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.3501 - acc: 0.8763 - top_2_accuracy: 0.9666 - MCC: 0.8176 - auc: 0.9791\n",
      "Epoch 00011: val_auc improved from 0.95820 to 0.95947, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 138s 2s/step - loss: 0.3501 - acc: 0.8763 - top_2_accuracy: 0.9666 - MCC: 0.8176 - auc: 0.9791 - val_loss: 0.5240 - val_acc: 0.8378 - val_top_2_accuracy: 0.9536 - val_MCC: 0.7614 - val_auc: 0.9595\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.3304 - acc: 0.8819 - top_2_accuracy: 0.9694 - MCC: 0.8260 - auc: 0.9818\n",
      "Epoch 00012: val_auc improved from 0.95947 to 0.96237, saving model to trained_models/classifiers/lamb_100_4096_256_imagenet_lr/barlow_0.005/classifier.h5\n",
      "92/92 [==============================] - 139s 2s/step - loss: 0.3304 - acc: 0.8819 - top_2_accuracy: 0.9694 - MCC: 0.8260 - auc: 0.9818 - val_loss: 0.5047 - val_acc: 0.8441 - val_top_2_accuracy: 0.9569 - val_MCC: 0.7702 - val_auc: 0.9624\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.3117 - acc: 0.8912 - top_2_accuracy: 0.9716 - MCC: 0.8397 - auc: 0.9838"
     ]
    }
   ],
   "source": [
    "# Trains a model for each fraction of data and save the results\n",
    "# for frac in [0.05, 0.1, 0.2, 0.4, 0.6, 0.8]:\n",
    "\n",
    "for lr in [0.005, 0.01, 0.02, 0.04, 0.08, 0.1]:\n",
    "    # !!! Change weights path here\n",
    "    for weights_path in ['trained_models/encoders/lamb_100_4096_256_imagenet/resnet.h5']:\n",
    "        config['encoder_weights_path'] = weights_path\n",
    "        \n",
    "        if weights_path is None:\n",
    "            # Training parameters for supervised models\n",
    "            model_type = 'supervised'\n",
    "            config['optimizer'] = 'adam'\n",
    "            config['lr_scheduler'] = 'plateau'\n",
    "            config['head_lr'] = 5e-3\n",
    "            config['encoder_lr'] = 5e-3\n",
    "        else:\n",
    "            # Training parameters for semi-supervised models\n",
    "            model_type = 'barlow'\n",
    "            config['optimizer'] = 'sgdw'\n",
    "            config['lr_scheduler'] = 'cosine'\n",
    "            config['head_lr'] = 0.03\n",
    "            config['encoder_lr'] = 0.03\n",
    "        \n",
    "        # Hyperparameter(s) to be fine-tuned\n",
    "#         config['train_split'] = frac\n",
    "        config['train_split'] = 0.2\n",
    "        config['head_lr'] = lr\n",
    "        config['encoder_lr'] = lr\n",
    "        config['model_name'] = f'{model_type}_{lr}'\n",
    "\n",
    "        configure_saving()\n",
    "\n",
    "        # Load dataset and model\n",
    "        datasets = load_datasets()\n",
    "        model = load_model(config_dict=config)\n",
    "\n",
    "        # Create training callbacks\n",
    "        callbacks = []\n",
    "        if config['patience'] is not None:\n",
    "            es = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=config['patience'])\n",
    "            callbacks.append(es)\n",
    "\n",
    "        if config['lr_scheduler'] == 'plateau':\n",
    "            reduce = ReduceLROnPlateau(\n",
    "                monitor='val_auc',\n",
    "                factor=0.2,\n",
    "                patience=3,\n",
    "                verbose=1\n",
    "            )\n",
    "            callbacks.append(reduce)\n",
    "\n",
    "        mc = ModelCheckpoint(\n",
    "            os.path.join(config['save_dir'], 'classifier.h5'),\n",
    "            monitor='val_auc', \n",
    "            mode='max',\n",
    "            verbose=1,\n",
    "            save_best_only=True, save_weights_only=True\n",
    "        )\n",
    "        callbacks.append(mc)\n",
    "        \n",
    "        callbacks.append(Logger())\n",
    "\n",
    "        # Print and save the configuration\n",
    "        log_config(config, save_config=True)\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            datasets[0],\n",
    "            epochs=config['epochs'],\n",
    "            steps_per_epoch=config['steps'][0],\n",
    "            validation_steps=config['steps'][1],\n",
    "            validation_data=datasets[1],\n",
    "            callbacks=callbacks,\n",
    "            class_weight=config['class_weight']\n",
    "        )\n",
    "\n",
    "        # Save the training history\n",
    "        with open(os.path.join(config['save_dir'], 'history.pickle'), 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # Load best model, save encoder weights (separately), and evaluate model\n",
    "        model.load_weights(os.path.join(config['save_dir'], 'classifier.h5'))\n",
    "        model.layers[1].save_weights(os.path.join(config['save_dir'], 'encoder.h5'))\n",
    "        model.evaluate(datasets[2], steps=config['steps'][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
