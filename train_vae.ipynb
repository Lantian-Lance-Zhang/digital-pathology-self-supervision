{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.models import vae\n",
    "from utils.train import callbacks as cb\n",
    "from utils.datasets import get_dataset_df\n",
    "from utils.misc import log_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_saving(model_name):\n",
    "    save_dir = os.path.join(config['root_save_dir'], model_name)\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(save_dir, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        input_ = input('save_dir already exists, continue? (Y/n)  >> ')\n",
    "        if input_ != 'Y':\n",
    "            raise ValueError\n",
    "            \n",
    "    with open(os.path.join(save_dir, 'config.json'), 'w') as file:\n",
    "        json.dump(config, file)\n",
    "        \n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    df = get_dataset_df(config['dataset_config'], config['random_seed'], mode='encoder')\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=config['validation_split'])\n",
    "    \n",
    "    datasets = []\n",
    "    for subset in ['training', 'validation']:\n",
    "        datagen = image_datagen.flow_from_dataframe(\n",
    "            df[df['split'] == 'train'],\n",
    "            shuffle=False,\n",
    "            seed=config['random_seed'],\n",
    "            target_size=config['image_shape'][:2],\n",
    "            batch_size=config['batch_size'],\n",
    "            subset=subset\n",
    "        )\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: [datagen.next()[0]],\n",
    "            output_types='float32', output_shapes=[None] * 4\n",
    "        )\n",
    "        dataset = dataset.map(lambda x: tf.clip_by_value(x, 0, 1), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.prefetch(config['prefetch'])\n",
    "        datasets.append(dataset)\n",
    "        \n",
    "        if subset == 'training':\n",
    "            config['steps_per_epoch'] = len(datagen)\n",
    "            print('Training steps per epoch:', config['steps_per_epoch'])\n",
    "        else:\n",
    "            config['val_steps_per_epoch'] = len(datagen)\n",
    "            print('Validation steps per epoch:', config['val_steps_per_epoch'])\n",
    "    \n",
    "    # One batch for generating visualizations (from validation set)\n",
    "    test_batch = next(iter(datasets[1].take(1)))\n",
    "\n",
    "    # Wrapper\n",
    "    def get_generator(ds):\n",
    "        def generator():\n",
    "            while True:\n",
    "                yield next(iter(ds))\n",
    "        return generator\n",
    "\n",
    "    return get_generator(datasets[0])(), get_generator(datasets[1])(), test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_seed          42\n",
      "epochs               100\n",
      "batch_size           256\n",
      "patience             None\n",
      "prefetch             8\n",
      "gpu_used             ['GPU:0', 'GPU:1', 'GPU:2', 'GPU:3']\n",
      "root_save_dir        trained_models/vaes\n",
      "lr                   0.0004\n",
      "image_shape          [224, 224, 3]\n",
      "validation_split     0.1\n",
      "dataset_config       {'split_file_path': 'datasets/tissue_classification/fold_test.csv', 'dataset_dir': 'datasets/tissue_classification/dataset_encoder'}\n",
      "latent_dim           512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('config/vae_config.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "config['epochs'] = 100\n",
    "log_config(config, 20)\n",
    "    \n",
    "np.random.seed(config['random_seed'])\n",
    "tf.random.set_seed(config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = configure_saving(model_name='vae_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 142201 validated image filenames belonging to 1 classes.\n",
      "Training steps per epoch: 556\n",
      "Found 15800 validated image filenames belonging to 1 classes.\n",
      "Validation steps per epoch: 62\n"
     ]
    }
   ],
   "source": [
    "dataset, dataset_val, test_batch = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(config['gpu_used'])\n",
    "print('Number of devices:', strategy.num_replicas_in_sync)\n",
    "\n",
    "with strategy.scope():\n",
    "    # Convolutional variational autoencoder\n",
    "    optimizer = tf.keras.optimizers.Adam(config['lr'])\n",
    "    model = vae.CVAE(\n",
    "        latent_dim=config['latent_dim'],\n",
    "        image_shape=config['image_shape']\n",
    "    )\n",
    "    model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    os.path.join(save_dir, 'model.h5'),\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "callbacks.append(mc)\n",
    "\n",
    "# Create visualizations (original, reconstructed, generated)\n",
    "vc = cb.VAECheckpoint(\n",
    "    model=model, \n",
    "    model_save_dir=save_dir, \n",
    "    latent_dim=config['latent_dim'], \n",
    "    test_batch=test_batch\n",
    ")\n",
    "callbacks.append(vc)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks.append(reduce_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 52 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=config['epochs'],\n",
    "    steps_per_epoch=config['steps_per_epoch'],\n",
    "    callbacks=callbacks,\n",
    "    validation_data=dataset_val,\n",
    "    validation_steps=config['val_steps_per_epoch']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, 'history.pickle'), 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from the best model\n",
    "model.load_weights(os.path.join(save_dir, 'model.h5'))\n",
    "model.encoder.save_weights(os.path.join(save_dir, 'encoder.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "projector (Sequential)       (None, 7, 7, 256)         6485248   \n",
      "_________________________________________________________________\n",
      "conv_block_0 (Sequential)    (None, 14, 14, 256)       591104    \n",
      "_________________________________________________________________\n",
      "conv_block_1 (Sequential)    (None, 28, 28, 128)       295552    \n",
      "_________________________________________________________________\n",
      "conv_block_2 (Sequential)    (None, 56, 56, 64)        74048     \n",
      "_________________________________________________________________\n",
      "conv_block_3 (Sequential)    (None, 112, 112, 32)      18592     \n",
      "_________________________________________________________________\n",
      "conv_block_4 (Sequential)    (None, 224, 224, 16)      4688      \n",
      "_________________________________________________________________\n",
      "conv_output (Conv2D)         (None, 224, 224, 3)       435       \n",
      "=================================================================\n",
      "Total params: 7,469,667\n",
      "Trainable params: 7,443,587\n",
      "Non-trainable params: 26,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.decoder.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
